{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question_eng', 'question_urdu', 'context_eng', 'context_urdu', 'answer_eng', 'answer_urdu', 'context_index', '__index_level_0__'],\n",
      "        num_rows: 495\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['question_eng', 'question_urdu', 'context_eng', 'context_urdu', 'answer_eng', 'answer_urdu', 'context_index', '__index_level_0__'],\n",
      "        num_rows: 124\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = load_from_disk(\"../../data/complete_dataset/\")\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Training\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "questions = []\n",
    "repeated = set()\n",
    "\n",
    "print('Validation')\n",
    "for i in range(len(dataset_dict['validation'])):\n",
    "    test_point = dataset_dict['validation'][i]\n",
    "\n",
    "    context = test_point['context_urdu']\n",
    "    question = test_point['question_urdu']\n",
    "\n",
    "    if context not in repeated:\n",
    "        repeated.add(context)\n",
    "        docs.append(context)\n",
    "\n",
    "    questions.append({'question': question, 'context': context, 'context_idx': docs.index(context)})\n",
    "\n",
    "print('Training')\n",
    "for i in range(len(dataset_dict['train'])):\n",
    "    test_point = dataset_dict['train'][i]\n",
    "\n",
    "    context = test_point['context_urdu']\n",
    "\n",
    "    if context not in repeated:\n",
    "        repeated.add(context)\n",
    "        docs.append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 305)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions), len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = embeddings.embed_documents([q['question'] for q in questions])\n",
    "docs_embeddings = embeddings.embed_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_answer(question_embedding, answer_embeddings):\n",
    "    similarities = cosine_similarity([question_embedding], answer_embeddings)\n",
    "    best_match_index = np.argsort(similarities)[0][::-1]\n",
    "    return best_match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_acc(k):\n",
    "    correct = 0\n",
    "    total = len(questions)\n",
    "\n",
    "    for i, pair in tqdm(enumerate(questions), desc=f\"Getting top {k}\", total=len(questions)):\n",
    "        context_idx = pair['context_idx']\n",
    "        question_embedding = question_embeddings[i]\n",
    "\n",
    "        nearest_indices = get_nearest_answer(question_embedding, docs_embeddings)[:k]\n",
    "\n",
    "        if context_idx in nearest_indices:\n",
    "            correct += 1\n",
    "\n",
    "    print(f'Top {k} Acc: {(correct / total) * 100 :.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting top 1: 100%|██████████| 124/124 [00:07<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Acc: 53.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting top 3: 100%|██████████| 124/124 [00:08<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Acc: 72.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting top 5: 100%|██████████| 124/124 [00:07<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Acc: 77.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_top_k_acc(1)\n",
    "get_top_k_acc(3)\n",
    "get_top_k_acc(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 1 Acc: `53.23%`  \n",
    "Top 3 Acc: `73.39%`  \n",
    "Top 5 Acc: `77.42%`  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urdu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
